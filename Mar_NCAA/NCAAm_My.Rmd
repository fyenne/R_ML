---
title: "NCAAm_my"
author: "Siming Yan"
date: "3/8/2021"
output: html_document
---

```{r}
library(caret)
```

```{r}
 
train_data_my  = data_matrix[, features]
train_label_my = data_matrix$ResultDiff



train_label_my = train_label_my %>% data.frame()
names(train_label_my) = "train_label_my"
train_label_my = train_label_my %>% mutate(train_label_my =ifelse(train_label_my > 0, "win", "loss"))
# train_label_my %>% table
train_label_my  = train_label_my$train_label_my %>% as.factor()

# train_label_my
```

 
```{r}
trControl = trainControl(
    method = 'cv',
    number = 10,
    # summaryFunction = giniSummary,
    classProbs = TRUE,
    verboseIter = TRUE,
    allowParallel = TRUE)

tuneGridXGB <- expand.grid(
    nrounds = c(450, 500, 750),
    max_depth = c(4, 6),
    eta = c(0.02, 0.05, 0.01),
    gamma = c(.1, 1, 10),
    colsample_bytree = c(0.75, .9),
    subsample = c(0.750),
    min_child_weight = c(40))
```

```{r}
library(doParallel)
cl <- makePSOCKcluster(8)
registerDoParallel(cl)
# stopCluster(cl)
# save.image("./based_tune_caret.RData")
```

```{r}
start <- Sys.time()

# train the xgboost learner
xgbmod <- train(
    x = train_data_my,
    y = train_label_my,
    method = 'xgbTree',
    metric = "Accuracy",
    # metric = 'NormalizedGini',
    trControl = trControl,
    tuneGrid = tuneGridXGB,
    verbose = T)


print(Sys.time() - start)
xgbmod$bestTune #500	4	0.05	10	0.9	40	0.75

```

```{r}
# smooth.spline(x = xgbmod$pred, y = ifelse(data_matrix$ResultDiff > 0, 1, 0))
```

```{r}
sub$Season = as.numeric(substring(sub$ID,1,4))
sub$T1 = as.numeric(substring(sub$ID,6,9))
sub$T2 = as.numeric(substring(sub$ID,11,14))

Z = sub %>% 
  left_join(season_summary_X1, by = c("Season", "T1")) %>% 
  left_join(season_summary_X2, by = c("Season", "T2")) %>%
  left_join(select(seeds, Season, T1 = TeamID, Seed1 = Seed), by = c("Season", "T1")) %>% 
  left_join(select(seeds, Season, T2 = TeamID, Seed2 = Seed), by = c("Season", "T2")) %>% 
  mutate(SeedDiff = Seed1 - Seed2) %>%
  left_join(select(quality, Season, T1 = Team_Id, quality_march_T1 = quality), by = c("Season", "T1")) %>%
  left_join(select(quality, Season, T2 = Team_Id, quality_march_T2 = quality), by = c("Season", "T2"))
```

```{r}
test_my = Z[, features]
# names(test_my)[!names(test_my) %in% names(train_data_my)]
# names(train_data_my)[!names(train_data_my) %in% names(test_my)]
test_my = test_my[, names(train_data_my)]
# names(test_my)
# names(train_data_my)
```


```{r}
preds <- predict(xgbmod, newdata = test_my, type = "prob")
preds
sub$Pred = preds$win
sub = sub[,c(1,3)]
sub
write.csv(sub, "./sub_m_1.csv")

# .0.49459 no medal

```

 





## caret tune 2

```{r}
# input_x <- as.matrix(select(tr_treated, -SalePrice_clean))
# input_y <- tr_treated$SalePrice_clean

input_x <- as.matrix(caret_tune_dada)
input_y <- y_train
```


```{r}
# run with default paras 
grid_default <- expand.grid(
  nrounds = 10,
  max_depth = 6,
  eta = 0.3,
  gamma = 0,
  colsample_bytree = 1,
  min_child_weight = 1,
  subsample = 1
)

train_control <- caret::trainControl(
  method = "none",
  verboseIter = F, # no training log
  allowParallel = TRUE # FALSE for reproducible results 
)

xgb_base <- caret::train(
  x = input_x,
  y = input_y,
  trControl = train_control,
  tuneGrid = grid_default,
  method = "xgbTree",
  verbose = TRUE
)
 
```